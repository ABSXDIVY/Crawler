#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘æ”¹å§”æ”¿ç­–é™„ä»¶ä¿¡æ¯æ‹†è§£å™¨
å¯¹Excelæ–‡ä»¶Sheet3çš„é™„ä»¶ä¿¡æ¯è¿›è¡Œæ‹†è§£ï¼Œå°†åŒ…å«å¤šä¸ªé™„ä»¶çš„è¡Œæ‹†åˆ†æˆå¤šè¡Œï¼Œå¹¶æ ¹æ®é“¾æ¥åç¼€è‡ªåŠ¨å¡«å…¥æ–‡ä»¶ç±»å‹
"""

import pandas as pd
import re
import os
import logging
from datetime import datetime
from urllib.parse import urlparse

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/attachment_splitter.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class AttachmentSplitter:
    """é™„ä»¶ä¿¡æ¯æ‹†è§£å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‹†è§£å™¨"""
        # æ–‡ä»¶ç±»å‹æ˜ å°„
        self.file_type_mapping = {
            '.pdf': 'PDF',
            '.ofd': 'OFD',
            '.doc': 'Word',
            '.docx': 'Word',
            '.xls': 'Excel',
            '.xlsx': 'Excel',
            '.ppt': 'PowerPoint',
            '.pptx': 'PowerPoint',
            '.txt': 'æ–‡æœ¬æ–‡ä»¶',
            '.zip': 'å‹ç¼©æ–‡ä»¶',
            '.rar': 'å‹ç¼©æ–‡ä»¶',
            '.7z': 'å‹ç¼©æ–‡ä»¶',
            '.jpg': 'å›¾ç‰‡æ–‡ä»¶',
            '.jpeg': 'å›¾ç‰‡æ–‡ä»¶',
            '.png': 'å›¾ç‰‡æ–‡ä»¶',
            '.gif': 'å›¾ç‰‡æ–‡ä»¶',
            '.bmp': 'å›¾ç‰‡æ–‡ä»¶',
            '.tiff': 'å›¾ç‰‡æ–‡ä»¶',
            '.mp4': 'è§†é¢‘æ–‡ä»¶',
            '.avi': 'è§†é¢‘æ–‡ä»¶',
            '.mov': 'è§†é¢‘æ–‡ä»¶',
            '.wmv': 'è§†é¢‘æ–‡ä»¶',
            '.mp3': 'éŸ³é¢‘æ–‡ä»¶',
            '.wav': 'éŸ³é¢‘æ–‡ä»¶',
            '.flv': 'éŸ³é¢‘æ–‡ä»¶',
            '.html': 'ç½‘é¡µæ–‡ä»¶',
            '.htm': 'ç½‘é¡µæ–‡ä»¶',
            '.xml': 'XMLæ–‡ä»¶',
            '.json': 'JSONæ–‡ä»¶',
            '.csv': 'CSVæ–‡ä»¶',
            '.rtf': 'RTFæ–‡ä»¶',
            '.odt': 'OpenDocument',
            '.ods': 'OpenDocument',
            '.odp': 'OpenDocument'
        }
        
        logging.info("é™„ä»¶æ‹†è§£å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def detect_file_type(self, url):
        """æ ¹æ®URLåç¼€æ£€æµ‹æ–‡ä»¶ç±»å‹"""
        if not url or pd.isna(url):
            return 'æœªçŸ¥ç±»å‹'
        
        try:
            # è§£æURL
            parsed_url = urlparse(str(url))
            path = parsed_url.path.lower()
            
            # æŸ¥æ‰¾æ–‡ä»¶æ‰©å±•å
            for ext, file_type in self.file_type_mapping.items():
                if path.endswith(ext):
                    return file_type
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ‰©å±•åï¼Œå°è¯•ä»URLä¸­æå–
            if '.' in path:
                ext = '.' + path.split('.')[-1]
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„æ‰©å±•å
                if ext in self.file_type_mapping:
                    return self.file_type_mapping[ext]
                else:
                    return f'å…¶ä»–æ–‡ä»¶({ext})'
            
            # å°è¯•ä»æŸ¥è¯¢å‚æ•°ä¸­æå–æ–‡ä»¶ç±»å‹
            if parsed_url.query:
                query_lower = parsed_url.query.lower()
                for ext, file_type in self.file_type_mapping.items():
                    if ext in query_lower:
                        return file_type
            
            return 'æœªçŸ¥ç±»å‹'
        except Exception as e:
            logging.warning(f"æ£€æµ‹æ–‡ä»¶ç±»å‹æ—¶å‡ºé”™: {e}, URL: {url}")
            return 'æœªçŸ¥ç±»å‹'
    
    def split_attachments(self, attachment_names, attachment_links):
        """æ‹†è§£é™„ä»¶åç§°å’Œé“¾æ¥"""
        if pd.isna(attachment_names) or pd.isna(attachment_links):
            return []
        
        names_str = str(attachment_names).strip()
        links_str = str(attachment_links).strip()
        
        if not names_str or not links_str:
            return []
        
        # é¦–å…ˆæå–æ‰€æœ‰é“¾æ¥
        links = self.extract_all_links(links_str)
        
        if not links:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é“¾æ¥ï¼Œè¿”å›å•ä¸ªé™„ä»¶
            return [{
                'é™„ä»¶åç§°': names_str,
                'é™„ä»¶é“¾æ¥': links_str,
                'æ–‡ä»¶ç±»å‹': self.detect_file_type(links_str)
            }]
        
        # æ ¹æ®é“¾æ¥æ•°é‡å†³å®šæ‹†åˆ†ç­–ç•¥
        if len(links) == 1:
            # åªæœ‰ä¸€ä¸ªé“¾æ¥ï¼Œè¿”å›å•ä¸ªé™„ä»¶
            return [{
                'é™„ä»¶åç§°': names_str,
                'é™„ä»¶é“¾æ¥': links_str,
                'æ–‡ä»¶ç±»å‹': self.detect_file_type(links_str)
            }]
        
        # å¤šä¸ªé“¾æ¥ï¼Œéœ€è¦æ‹†åˆ†åç§°
        name_parts = self.split_names_by_links(names_str, links_str, links)
        
        # æ„å»ºé™„ä»¶åˆ—è¡¨
        attachments = []
        for i, (name, link) in enumerate(zip(name_parts, links)):
            if name and link:
                attachments.append({
                    'é™„ä»¶åç§°': name,
                    'é™„ä»¶é“¾æ¥': link,
                    'æ–‡ä»¶ç±»å‹': self.detect_file_type(link)
                })
        
        return attachments
    
    def extract_all_links(self, links_str):
        """æå–æ‰€æœ‰httpé“¾æ¥"""
        links = []
        
        # åªåŒ¹é…http/httpsé“¾æ¥
        link_patterns = [
            r'https?://[^\s\n,;ï¼Œï¼›ã€|]+',  # HTTP/HTTPSé“¾æ¥
        ]
        
        for pattern in link_patterns:
            found_links = re.findall(pattern, links_str)
            links.extend(found_links)
        
        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        unique_links = []
        for link in links:
            if link not in seen:
                seen.add(link)
                unique_links.append(link)
        
        logging.info(f"æå–åˆ° {len(unique_links)} ä¸ªhttpé“¾æ¥")
        return unique_links
    
    def split_names_by_links(self, names_str, links_str, links):
        """æ ¹æ®é“¾æ¥æ‹†åˆ†åç§° - ä»…æ ¹æ®httpå­—æ®µåˆ†è§£ï¼Œåç§°æŒ‰åºå·æˆ–æ˜æ˜¾ç¬¦å·åˆ†è§£"""
        if len(links) == 1:
            return [names_str]
        
        logging.info(f"é“¾æ¥æ•°é‡: {len(links)}")
        
        # ç­–ç•¥1: å°è¯•æ ¹æ®æ˜æ˜¾çš„åºå·æˆ–ç¬¦å·æ‹†åˆ†åç§°
        name_parts = self.split_by_clear_markers(names_str, len(links))
        if len(name_parts) == len(links):
            logging.info(f"æ ¹æ®æ˜æ˜¾æ ‡è®°æ‹†åˆ†æˆåŠŸï¼Œå…± {len(name_parts)} ä¸ª")
            return name_parts
        
        # ç­–ç•¥2: å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦æ¥æ‹†åˆ†åç§°
        separators = [
            '\n',           # æ¢è¡Œç¬¦
            'ï¼›',           # ä¸­æ–‡åˆ†å·
            ';',            # è‹±æ–‡åˆ†å·
            'ï¼Œ',           # ä¸­æ–‡é€—å·
            ',',            # è‹±æ–‡é€—å·
            'ã€',           # ä¸­æ–‡é¡¿å·
            '|',            # ç«–çº¿
            '||',           # åŒç«–çº¿
        ]
        
        # å°è¯•æ‰¾åˆ°åˆé€‚çš„åˆ†éš”ç¬¦
        for sep in separators:
            if sep in names_str:
                name_parts = [part.strip() for part in names_str.split(sep) if part.strip()]
                if len(name_parts) == len(links):
                    logging.info(f"ä½¿ç”¨åˆ†éš”ç¬¦ '{sep}' æ‹†è§£é™„ä»¶åç§°ï¼Œå…± {len(name_parts)} ä¸ª")
                    return name_parts
        
        # ç­–ç•¥3: å¦‚æœæ— æ³•æ‹†åˆ†ï¼Œä½¿ç”¨é»˜è®¤çš„åºå·åˆ†é…
        name_parts = self.split_by_default_sequence(names_str, len(links))
        logging.info(f"ä½¿ç”¨é»˜è®¤åºå·åˆ†é…ï¼Œå…± {len(name_parts)} ä¸ª")
        
        return name_parts
    
    def split_by_clear_markers(self, names_str, link_count):
        """æ ¹æ®æ˜æ˜¾çš„åºå·æˆ–ç¬¦å·æ‹†åˆ†åç§°"""
        name_parts = []
        
        # æŸ¥æ‰¾æ˜æ˜¾çš„åºå·æ¨¡å¼
        patterns = [
            r'(\d+)[\.ã€\)ï¼‰]',  # æ•°å­—+ç‚¹/é¡¿å·/æ‹¬å·
            r'[ï¼ˆ\(](\d+)[ï¼‰\)]',  # æ‹¬å·ä¸­çš„æ•°å­—
            r'ç¬¬(\d+)',          # ç¬¬X
            r'é™„ä»¶(\d+)',        # é™„ä»¶X
        ]
        
        # å°è¯•æ‰¾åˆ°åºå·ä½ç½®
        marker_positions = []
        for pattern in patterns:
            matches = list(re.finditer(pattern, names_str))
            if len(matches) == link_count:
                marker_positions = [(m.start(), m.group()) for m in matches]
                break
        
        if marker_positions:
            # æŒ‰åºå·ä½ç½®æ‹†åˆ†
            marker_positions.sort(key=lambda x: x[0])
            
            for i, (pos, marker) in enumerate(marker_positions):
                if i == 0:
                    # ç¬¬ä¸€ä¸ªåºå·ï¼Œå–ä»å¼€å§‹åˆ°ä¸‹ä¸€ä¸ªåºå·ä¹‹å‰çš„å†…å®¹
                    if i + 1 < len(marker_positions):
                        end_pos = marker_positions[i + 1][0]
                        name_part = names_str[:end_pos].strip()
                    else:
                        name_part = names_str.strip()
                else:
                    # å…¶ä»–åºå·ï¼Œå–ä»å½“å‰åºå·åˆ°ä¸‹ä¸€ä¸ªåºå·ä¹‹å‰çš„å†…å®¹
                    if i + 1 < len(marker_positions):
                        end_pos = marker_positions[i + 1][0]
                        name_part = names_str[pos:end_pos].strip()
                    else:
                        name_part = names_str[pos:].strip()
                
                if name_part:
                    name_parts.append(name_part)
        
        return name_parts
    
    def split_by_default_sequence(self, names_str, link_count):
        """ä½¿ç”¨é»˜è®¤çš„åºå·åˆ†é…"""
        name_parts = []
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªé“¾æ¥ï¼Œè¿”å›åŸåç§°
        if link_count == 1:
            return [names_str]
        
        # å¯¹äºå¤šä¸ªé“¾æ¥ï¼Œå°è¯•æ™ºèƒ½åˆ†é…
        # æŸ¥æ‰¾å¯èƒ½çš„è‡ªç„¶åˆ†å‰²ç‚¹
        split_points = []
        
        # æŸ¥æ‰¾å¸¸è§çš„åˆ†å‰²ç‚¹
        split_patterns = [
            r'[ã€‚ï¼ï¼Ÿï¼›]',  # å¥å·ã€æ„Ÿå¹å·ã€é—®å·ã€åˆ†å·
            r'[ï¼Œ,]',      # é€—å·
            r'[ã€]',       # é¡¿å·
            r'\s+',        # å¤šä¸ªç©ºæ ¼
        ]
        
        for pattern in split_patterns:
            matches = list(re.finditer(pattern, names_str))
            if len(matches) >= link_count - 1:
                split_points = [m.end() for m in matches[:link_count-1]]
                break
        
        if split_points:
            # æ ¹æ®åˆ†å‰²ç‚¹æ‹†åˆ†
            last_pos = 0
            for pos in split_points:
                name_part = names_str[last_pos:pos].strip()
                if name_part:
                    name_parts.append(name_part)
                last_pos = pos
            
            # æ·»åŠ æœ€åä¸€éƒ¨åˆ†
            if last_pos < len(names_str):
                name_part = names_str[last_pos:].strip()
                if name_part:
                    name_parts.append(name_part)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è‡ªç„¶åˆ†å‰²ç‚¹ï¼ŒæŒ‰é•¿åº¦å¹³å‡åˆ†é…
            part_length = len(names_str) // link_count
            for i in range(link_count):
                if i == 0:
                    name_part = names_str[:part_length].strip()
                elif i == link_count - 1:
                    name_part = names_str[part_length:].strip()
                else:
                    start = i * part_length
                    end = (i + 1) * part_length
                    name_part = names_str[start:end].strip()
                
                if name_part:
                    name_parts.append(name_part)
        
        # ç¡®ä¿æ•°é‡åŒ¹é…
        while len(name_parts) < link_count:
            name_parts.append(f"é™„ä»¶{len(name_parts)+1}")
        
        return name_parts[:link_count]
    
    def get_file_extension(self, url):
        """è·å–æ–‡ä»¶æ‰©å±•å"""
        try:
            parsed_url = urlparse(str(url))
            path = parsed_url.path.lower()
            if '.' in path:
                return '.' + path.split('.')[-1]
            return ''
        except:
            return ''
    
    def split_by_extensions(self, names_str, links, extensions):
        """æ ¹æ®æ–‡ä»¶åç¼€æ‹†åˆ†åç§°"""
        name_parts = []
        
        # æŸ¥æ‰¾åç§°ä¸­æ˜¯å¦åŒ…å«å¯¹åº”çš„åç¼€
        for i, (link, ext) in enumerate(zip(links, extensions)):
            if ext:
                # åœ¨åç§°ä¸­æŸ¥æ‰¾åŒ…å«è¯¥åç¼€çš„éƒ¨åˆ†
                ext_pattern = re.escape(ext)
                matches = re.findall(f'[^\\s\\n,;ï¼Œï¼›ã€|]*{ext_pattern}[^\\s\\n,;ï¼Œï¼›ã€|]*', names_str)
                
                if matches:
                    # æ‰¾åˆ°åŒ¹é…çš„åç¼€ï¼Œä½¿ç”¨å¯¹åº”çš„åç§°éƒ¨åˆ†
                    name_part = matches[0]
                    name_parts.append(name_part)
                    # ä»åŸåç§°ä¸­ç§»é™¤å·²åŒ¹é…çš„éƒ¨åˆ†
                    names_str = names_str.replace(name_part, '', 1)
                else:
                    # æ²¡æ‰¾åˆ°åŒ¹é…çš„åç¼€ï¼Œä½¿ç”¨é»˜è®¤æ‹†åˆ†
                    name_part = self.split_name_by_position(names_str, i, len(links))
                    name_parts.append(name_part)
            else:
                # æ²¡æœ‰åç¼€ï¼Œä½¿ç”¨é»˜è®¤æ‹†åˆ†
                name_part = self.split_name_by_position(names_str, i, len(links))
                name_parts.append(name_part)
        
        return name_parts
    
    def split_by_link_positions(self, names_str, links_str, links):
        """æ ¹æ®é“¾æ¥åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®æ¥æ‹†åˆ†åç§°"""
        name_parts = []
        
        # æŸ¥æ‰¾æ¯ä¸ªé“¾æ¥åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®
        link_positions = []
        for link in links:
            pos = links_str.find(link)
            if pos != -1:
                link_positions.append((pos, link))
        
        # æŒ‰ä½ç½®æ’åº
        link_positions.sort(key=lambda x: x[0])
        
        # æ ¹æ®é“¾æ¥ä½ç½®æ‹†åˆ†åç§°
        for i, (pos, link) in enumerate(link_positions):
            name_part = self.split_name_by_position(names_str, i, len(links))
            name_parts.append(name_part)
        
        return name_parts
    
    def split_name_by_position(self, names_str, index, total_count):
        """æ ¹æ®ä½ç½®æ‹†åˆ†åç§°"""
        if total_count == 1:
            return names_str
        
        # è®¡ç®—æ¯ä¸ªéƒ¨åˆ†çš„é•¿åº¦
        part_length = len(names_str) // total_count
        
        if index == 0:
            # ç¬¬ä¸€ä¸ªéƒ¨åˆ†
            name_part = names_str[:part_length].strip()
        elif index == total_count - 1:
            # æœ€åä¸€ä¸ªéƒ¨åˆ†
            name_part = names_str[part_length:].strip()
        else:
            # ä¸­é—´éƒ¨åˆ†
            start = index * part_length
            end = (index + 1) * part_length
            name_part = names_str[start:end].strip()
        
        # æ¸…ç†åç§°
        name_part = self.clean_attachment_name(name_part)
        if not name_part:
            name_part = f"é™„ä»¶{index+1}"
        
        return name_part
    
    def clean_attachment_name(self, name):
        """æ¸…ç†é™„ä»¶åç§°"""
        if not name:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        name = re.sub(r'\s+', ' ', name.strip())
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’Œå¸¸ç”¨æ ‡ç‚¹
        name = re.sub(r'[^\w\s\u4e00-\u9fff\-_\.\(\)ï¼ˆï¼‰]+', '', name)
        
        return name.strip()
    

    
    def process_excel_file(self, input_file, output_file):
        """å¤„ç†Excelæ–‡ä»¶"""
        try:
            logging.info(f"å¼€å§‹å¤„ç†Excelæ–‡ä»¶: {input_file}")
            
            # è¯»å–Sheet3 - æ”¿ç­–é™„ä»¶
            df = pd.read_excel(input_file, sheet_name='æ”¿ç­–é™„ä»¶')
            logging.info(f"è¯»å–åˆ° {len(df)} æ¡é™„ä»¶è®°å½•")
            
            # åˆ›å»ºæ–°çš„æ‹†è§£æ•°æ®
            split_data = []
            
            for index, row in df.iterrows():
                policy_title = row['æ”¿ç­–æ ‡é¢˜']
                attachment_names = row['é™„ä»¶åç§°']
                attachment_links = row['é™„ä»¶é“¾æ¥']
                
                logging.info(f"å¤„ç†æ”¿ç­–é™„ä»¶: {policy_title}")
                
                # æ‹†è§£é™„ä»¶ä¿¡æ¯
                attachments = self.split_attachments(attachment_names, attachment_links)
                
                if not attachments:
                    # å¦‚æœæ²¡æœ‰é™„ä»¶ï¼Œæ·»åŠ ç©ºè®°å½•
                    split_data.append({
                        'æ”¿ç­–åˆ†ç±»': row['æ”¿ç­–åˆ†ç±»'],
                        'æ”¿ç­–æ ‡é¢˜': policy_title,
                        'æ–‡å·': row['æ–‡å·'],
                        'å‘å¸ƒæ—¥æœŸ': row['å‘å¸ƒæ—¥æœŸ'],
                        'æ”¿ç­–é“¾æ¥': row['æ”¿ç­–é“¾æ¥'],
                        'é™„ä»¶åºå·': 1,
                        'é™„ä»¶åç§°': '',
                        'é™„ä»¶é“¾æ¥': '',
                        'æ–‡ä»¶ç±»å‹': 'æ— é™„ä»¶'
                    })
                else:
                    # æ·»åŠ æ‹†è§£åçš„é™„ä»¶
                    for i, attachment in enumerate(attachments, 1):
                        split_data.append({
                            'æ”¿ç­–åˆ†ç±»': row['æ”¿ç­–åˆ†ç±»'],
                            'æ”¿ç­–æ ‡é¢˜': policy_title,
                            'æ–‡å·': row['æ–‡å·'],
                            'å‘å¸ƒæ—¥æœŸ': row['å‘å¸ƒæ—¥æœŸ'],
                            'æ”¿ç­–é“¾æ¥': row['æ”¿ç­–é“¾æ¥'],
                            'é™„ä»¶åºå·': i,
                            'é™„ä»¶åç§°': attachment['é™„ä»¶åç§°'],
                            'é™„ä»¶é“¾æ¥': attachment['é™„ä»¶é“¾æ¥'],
                            'æ–‡ä»¶ç±»å‹': attachment['æ–‡ä»¶ç±»å‹']
                        })
                
                logging.info(f"æ”¿ç­– '{policy_title}' é™„ä»¶æ‹†è§£å®Œæˆï¼Œå…± {len(attachments)} ä¸ªé™„ä»¶")
            
            # åˆ›å»ºæ–°çš„DataFrame
            split_df = pd.DataFrame(split_data)
            
            # ä¿å­˜åˆ°æ–°çš„Excelæ–‡ä»¶
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                split_df.to_excel(writer, sheet_name='æ”¿ç­–é™„ä»¶_æ‹†è§£', index=False)
            
            logging.info(f"é™„ä»¶æ‹†è§£å®Œæˆï¼Œå…±ç”Ÿæˆ {len(split_data)} æ¡è®°å½•")
            logging.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            self.print_statistics(split_df)
            
            return split_df
            
        except Exception as e:
            logging.error(f"å¤„ç†Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            raise
    
    def print_statistics(self, df):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        logging.info("\nğŸ“Š é™„ä»¶æ‹†è§£ç»Ÿè®¡ä¿¡æ¯:")
        logging.info(f"æ€»é™„ä»¶æ•°: {len(df)}")
        logging.info(f"æ¶‰åŠæ”¿ç­–æ•°: {df['æ”¿ç­–æ ‡é¢˜'].nunique()}")
        
        # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        file_type_counts = df['æ–‡ä»¶ç±»å‹'].value_counts()
        logging.info(f"æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        for file_type, count in file_type_counts.head(10).items():
            logging.info(f"  {file_type}: {count} ä¸ª")
        
        # æœ‰é™„ä»¶çš„æ”¿ç­–ç»Ÿè®¡
        policies_with_attachments = df[df['æ–‡ä»¶ç±»å‹'] != 'æ— é™„ä»¶']['æ”¿ç­–æ ‡é¢˜'].nunique()
        policies_without_attachments = df[df['æ–‡ä»¶ç±»å‹'] == 'æ— é™„ä»¶']['æ”¿ç­–æ ‡é¢˜'].nunique()
        
        logging.info(f"æœ‰é™„ä»¶çš„æ”¿ç­–æ•°: {policies_with_attachments}")
        logging.info(f"æ— é™„ä»¶çš„æ”¿ç­–æ•°: {policies_without_attachments}")
        
        # é™„ä»¶æ•°é‡åˆ†å¸ƒ
        attachment_counts = df.groupby('æ”¿ç­–æ ‡é¢˜')['é™„ä»¶åºå·'].max()
        logging.info(f"å¹³å‡æ¯ä¸ªæ”¿ç­–é™„ä»¶æ•°: {attachment_counts.mean():.1f}")
        logging.info(f"æœ€å¤šé™„ä»¶æ•°: {attachment_counts.max()}")
        logging.info(f"æœ€å°‘é™„ä»¶æ•°: {attachment_counts.min()}")

def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs('logs', exist_ok=True)
    
    # è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶
    input_file = 'policy_data_full.xlsx'
    output_file = 'policy_attachments_split.xlsx'
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        logging.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    # åˆ›å»ºæ‹†è§£å™¨
    splitter = AttachmentSplitter()
    
    # å¤„ç†æ–‡ä»¶
    try:
        splitter.process_excel_file(input_file, output_file)
        logging.info("ğŸ‰ é™„ä»¶æ‹†è§£å¤„ç†å®Œæˆï¼")
    except Exception as e:
        logging.error(f"å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    main() 
